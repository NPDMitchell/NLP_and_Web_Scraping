{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = pd.read_csv('jobs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>total_pay</th>\n",
       "      <th>Simple_Title</th>\n",
       "      <th>Job_Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lead data architect</td>\n",
       "      <td>me</td>\n",
       "      <td>melbourne</td>\n",
       "      <td>div data-automation=\"mobiletemplate\" class=\"_2...</td>\n",
       "      <td>159750.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>Middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data wrangling expert/asset performance analyst</td>\n",
       "      <td>peak services</td>\n",
       "      <td>melbourne</td>\n",
       "      <td>div data-automation=\"mobiletemplate\" class=\"_2...</td>\n",
       "      <td>201500.0</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data scientist / data analyst</td>\n",
       "      <td>randstad - technologies</td>\n",
       "      <td>melbourne</td>\n",
       "      <td>div data-automation=\"mobiletemplate\" class=\"_2...</td>\n",
       "      <td>201500.0</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data analyst</td>\n",
       "      <td>nab</td>\n",
       "      <td>melbourne</td>\n",
       "      <td>div data-automation=\"mobiletemplate\" class=\"_2...</td>\n",
       "      <td>201500.0</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>analyst chapter lead (cloud and big data</td>\n",
       "      <td>anz</td>\n",
       "      <td>melbourne</td>\n",
       "      <td>div data-automation=\"mobiletemplate\" class=\"_2...</td>\n",
       "      <td>201500.0</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Middle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Title                  Company  \\\n",
       "0                              lead data architect                       me   \n",
       "1  data wrangling expert/asset performance analyst            peak services   \n",
       "2                    data scientist / data analyst  randstad - technologies   \n",
       "3                                     data analyst                      nab   \n",
       "4         analyst chapter lead (cloud and big data                      anz   \n",
       "\n",
       "    Location                                        Description  total_pay  \\\n",
       "0  melbourne  div data-automation=\"mobiletemplate\" class=\"_2...   159750.0   \n",
       "1  melbourne  div data-automation=\"mobiletemplate\" class=\"_2...   201500.0   \n",
       "2  melbourne  div data-automation=\"mobiletemplate\" class=\"_2...   201500.0   \n",
       "3  melbourne  div data-automation=\"mobiletemplate\" class=\"_2...   201500.0   \n",
       "4  melbourne  div data-automation=\"mobiletemplate\" class=\"_2...   201500.0   \n",
       "\n",
       "  Simple_Title Job_Level  \n",
       "0        Other    Middle  \n",
       "1      Analyst    Middle  \n",
       "2      Analyst    Middle  \n",
       "3      Analyst    Middle  \n",
       "4      Analyst    Middle  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.22626788036411"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_title = jobs.Simple_Title.value_counts().max()/len(jobs.Simple_Title) * 100\n",
    "baseline_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the Job Category from the description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = jobs.Description.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = jobs.Simple_Title.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the train and test sets for both Count Vectorizer and TF-TDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 3), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec = CountVectorizer(stop_words='english', ngram_range=(1,3))\n",
    "cvec.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cv = cvec.transform(X_train)\n",
    "X_test_cv = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vec = TfidfVectorizer(stop_words='english', ngram_range=(1,3))\n",
    "tfidf_vec.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf_vec.transform(X_train)\n",
    "X_test_tfidf = tfidf_vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function to try different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, X_train, y_train, X_test):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = classifier.predict(X_test)\n",
    "      \n",
    "    return accuracy_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MULTINOMIAL NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Count Vectors:  0.6010362694300518\n",
      "NB, TF-IDF:  0.5284974093264249\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(MultinomialNB(), X_train_cv, y_train, X_test_cv)\n",
    "print (\"NB, Count Vectors: \", accuracy)\n",
    "\n",
    "accuracy = train_model(MultinomialNB(), X_train_tfidf, y_train, X_test_tfidf)\n",
    "print (\"NB, TF-IDF: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR, Count Vectors:  0.7357512953367875\n",
      "LR, TF-IDF:  0.5647668393782384\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(LogisticRegression(random_state=30), X_train_cv, y_train, X_test_cv)\n",
    "print (\"LR, Count Vectors: \", accuracy)\n",
    "\n",
    "accuracy = train_model(LogisticRegression(random_state=30), X_train_tfidf, y_train, X_test_tfidf)\n",
    "print (\"LR, TF-IDF: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUPPORT VECTOR CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC, TF-IDF:  0.5284974093264249\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(SVC(random_state=30), X_train_tfidf, y_train, X_test_tfidf)\n",
    "print (\"SVC, TF-IDF: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, Count Vectors:  0.5854922279792746\n",
      "RF, TF-IDF:  0.616580310880829\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(RandomForestClassifier(random_state=30), X_train_cv, y_train, X_test_cv)\n",
    "print (\"RF, Count Vectors: \", accuracy)\n",
    "\n",
    "accuracy = train_model(RandomForestClassifier(random_state=30), X_train_tfidf, y_train, X_test_tfidf)\n",
    "print (\"RF, TF-IDF: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf-idf features for NMF...\n",
      "done in 0.354s.\n",
      "Extracting tf features for LDA...\n",
      "done in 0.281s.\n",
      "\n",
      "Fitting the NMF model (Frobenius norm) with tf-idf features, n_samples=2000 and n_features=1000...\n",
      "done in 0.418s.\n",
      "\n",
      "Topics in NMF model (Frobenius norm):\n",
      "Topic #0: li ul strong experience business skills management team work working requirements analysis support role ability xa0 systems reporting amp stakeholders\n",
      "Topic #1: br strong experience xa0 project ba master role work big skills analyst contract business company reporting client services working management\n",
      "Topic #2: xa0 experience sales regarded skills entry management br ms working energy support outstanding industry global growth com successfully customers join\n",
      "Topic #3: strong role research australia skills government work company experience www apply people position _blank month contract opportunity level recruitment target\n",
      "Topic #4: analytics insights marketing customer digital business science team learning development drive tools modelling machine strategic people analysis key solutions using\n",
      "Topic #5: contact 03 href true match com au tel _2zkuacf mailto ne1m3o8 melbourne 02 apply bi email talentinternational analyst experience information\n",
      "Topic #6: financial reporting business finance accounting performance commercial analysis role forecasting australia analyst modelling intelligence qualified senior monthly management investment manager\n",
      "Topic #7: macquarie banking careers ll diversity services team com technical operations customers digital facilitate want focus history working flexibility arrangements teams\n",
      "Topic #8: entry ll hays need new return succeed department temporary processing government date role copy position officer audit forward right hours\n",
      "Topic #9: em recruitment amp people audit 2018 health international committed best h2 check year diverse security strong opportunity database initiative policy\n",
      "\n",
      "Fitting the NMF model (generalized Kullback-Leibler divergence) with tf-idf features, n_samples=2000 and n_features=1000...\n",
      "done in 4.280s.\n",
      "\n",
      "Topics in NMF model (generalized Kullback-Leibler divergence):\n",
      "Topic #0: li analysis ul strong analytical analyst business role work working xa0 skills experience team years apply br management assist benefits\n",
      "Topic #1: br amp strong apply _2zkuacf xa0 role experience client company australian based team working true work new melbourne tel click\n",
      "Topic #2: xa0 australia amp applications skills strong xa0to activities required able working service provide systems management quality daily opportunity xa0and regulatory\n",
      "Topic #3: people em access opportunities _2zkuacf services new position applicants strong diverse offer zealand accurate information year career committed including opportunity\n",
      "Topic #4: amp analytics advanced ability development team drive xa0 business key best insights strategic stakeholders tools build working customer deliver achieve\n",
      "Topic #5: apply true ul _2zkuacf strong com sql contact match tel href python analytics successful experience solutions azure skills aws ne1m3o8\n",
      "Topic #6: analysis apply analyst stakeholders true activities requirements contact match _2zkuacf analyse ul years project tel ability href information process com\n",
      "Topic #7: agile application architecture ability technology systems technical team understanding experience technologies best quality working including solutions security based test apply\n",
      "Topic #8: ability au true match apply accuracy ul li mailto work attention href ne1m3o8 contact administration advanced skills advantage position role\n",
      "Topic #9: analytics bi amp sql ability advanced power reporting reports tableau address business requirements server solutions tools analysing ul report xa0\n",
      "\n",
      "Fitting LDA models with tf features, n_samples=2000 and n_features=1000...\n",
      "done in 2.978s.\n",
      "\n",
      "Topics in LDA model:\n",
      "Topic #0: br strong li xa0 nsw contact href 03 information policy transport experience apply business true match asset analyst au people\n",
      "Topic #1: edu university school research _blank target li http www strong href intelligence staff au position https warehouse description secure level\n",
      "Topic #2: li strong experience ul br xa0 business role skills apply working analysis work customer management sql ability team analyst amp\n",
      "Topic #3: strong br level experience xa0 azure communication role complex business skills school position growth solutions new analytical apply research com\n",
      "Topic #4: li br strong experience services support xa0 team business ul working children skills role work analytics development technical programs solutions\n",
      "Topic #5: strong br li experience xa0 role skills ul work working new excellent team ability wide government stakeholders key tools modelling\n",
      "Topic #6: li strong br xa0 ul experience business role skills work team working management apply analysis amp ability analytics contact reporting\n",
      "Topic #7: br strong xa0 li skills experience apply government return ul big communications match team note credit forward large testing cv\n",
      "Topic #8: linkedin senior industry em number architecture rapidly timely understanding monthly join engineer communications verbal sydney improvements talent azure strategy queries\n",
      "Topic #9: br strong li ll xa0 hays contact au com need match href true new role model department team victoria return\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_components = 10\n",
    "n_top_words = 20\n",
    "\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()\n",
    "\n",
    "\n",
    "print(\"Extracting tf-idf features for NMF...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,\n",
    "                                   max_features=n_features,\n",
    "                                   stop_words='english')\n",
    "t0 = time()\n",
    "tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "# Use tf (raw term count) features for LDA.\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "cv_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=n_features,\n",
    "                                stop_words='english')\n",
    "t0 = time()\n",
    "cv = cv_vectorizer.fit_transform(X_train)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model (Frobenius norm) with tf-idf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_components, random_state=1,\n",
    "          alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in NMF model (Frobenius norm):\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)\n",
    "\n",
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model (generalized Kullback-Leibler divergence) with \"\n",
    "      \"tf-idf features, n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_components, random_state=1,\n",
    "          beta_loss='kullback-leibler', solver='mu', max_iter=1000, alpha=.1,\n",
    "          l1_ratio=.5).fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in NMF model (generalized Kullback-Leibler divergence):\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)\n",
    "\n",
    "print(\"Fitting LDA models with tf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "lda = LatentDirichletAllocation(n_components=n_components, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "t0 = time()\n",
    "lda.fit(cv)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "cv_feature_names = cv_vectorizer.get_feature_names()\n",
    "print_top_words(lda, cv_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
